{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "\n",
    "This notebook shows how to train Mask RCNN sequentially so that one can train starting with synthetic data, then retrain models on manual segmentations for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set which GPU to use dynamically (e.g., \"4\" for GPU 4)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "DATA_DIR = os.path.abspath(\"../../../Data\")\n",
    "print(\"ROOT DIR:\", ROOT_DIR)\n",
    "print(\"Data Dir:\",DATA_DIR)\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "\n",
    "print(\"sys.prefix:\",sys.prefix)\n",
    "print(\"sys.executable:\",sys.executable)\n",
    "print(\"sys.path:\", sys.path)\n",
    "%matplotlib inline \n",
    "\n",
    "mrcnn_dir = os.path.dirname(modellib.__file__)\n",
    "model_file_path = os.path.join(mrcnn_dir,'model.py')\n",
    "print(\"mrcnn directory:\",mrcnn_dir)\n",
    "print(\"Path to model.py:\", model_file_path)\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(DATA_DIR, \"logs\")\n",
    "print(\"MODEL DIRECTORY:\", MODEL_DIR)\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "    \n",
    "print(\"COCO MODEL PATH:\", COCO_MODEL_PATH)\n",
    "\n",
    "\n",
    "#import tensorboard stuff\n",
    "#%load_ext tensorboard\n",
    "#import tensorflow as tf\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGEConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"SAGE\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1 #+ 1  # background + particle + cluster \n",
    "\n",
    "  # Input image resizing\n",
    "    # Generally, use the \"square\" resizing mode for training and predicting\n",
    "    # and it should work well in most cases. In this mode, images are scaled\n",
    "    # up such that the small side is = IMAGE_MIN_DIM, but ensuring that the\n",
    "    # scaling doesn't make the long side > IMAGE_MAX_DIM. Then the image is\n",
    "    # padded with zeros to make it a square so multiple images can be put\n",
    "    # in one batch.\n",
    "    # Available resizing modes:\n",
    "    # none:   No resizing or padding. Return the image unchanged.\n",
    "    # square: Resize and pad with zeros to get a square image\n",
    "    #         of size [max_dim, max_dim].\n",
    "    # pad64:  Pads width and height with zeros to make them multiples of 64.\n",
    "    #         If IMAGE_MIN_DIM or IMAGE_MIN_SCALE are not None, then it scales\n",
    "    #         up before padding. IMAGE_MAX_DIM is ignored in this mode.\n",
    "    #         The multiple of 64 is needed to ensure smooth scaling of feature\n",
    "    #         maps up and down the 6 levels of the FPN pyramid (2**6=64).\n",
    "    # crop:   Picks random crops from the image. First, scales the image based\n",
    "    #         on IMAGE_MIN_DIM and IMAGE_MIN_SCALE, then picks a random crop of\n",
    "    #         size IMAGE_MIN_DIM x IMAGE_MIN_DIM. Can be used in training only.\n",
    "    #         IMAGE_MAX_DIM is not used in this mode.\n",
    "    IMAGE_RESIZE_MODE = \"square\"\n",
    "    IMAGE_MIN_DIM = 1024\n",
    "    IMAGE_MAX_DIM = 1024\n",
    "    # Minimum scaling ratio. Checked after MIN_IMAGE_DIM and can force further\n",
    "    # up scaling. For example, if set to 2 then images are scaled up to double\n",
    "    # the width and height, or more, even if MIN_IMAGE_DIM doesn't require it.\n",
    "    # However, in 'square' mode, it can be overruled by IMAGE_MAX_DIM.\n",
    "    IMAGE_MIN_SCALE = 0\n",
    "    # Number of color channels per image. RGB = 3, grayscale = 1, RGB-D = 4\n",
    "    # Changing this requires other changes in the code. See the WIKI for more\n",
    "    # details: https://github.com/matterport/Mask_RCNN/wiki\n",
    "    IMAGE_CHANNEL_COUNT = 3 #images are grayscale(8bit) so may need to change to 1\n",
    "    \n",
    "    MEAN_PIXEL = np.array([123.7, 116.8, 103.9]) #may need to change to one value for grayscale\n",
    "\n",
    "    # Default \n",
    "    RPN_ANCHOR_SCALES = (32, 64, 128, 256,512) #(16,32,64,128,256)#  # anchor side in pixels\n",
    "                #opt to change to smaller values to recognize smaller particles as well\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 256\n",
    "        #increase from 128 to 256 to allow attempt more \n",
    "    DETECTION_MAX_INSTANCES = 200 #increase from 100 to 200\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH =7 # 76 for 200 #20 for 60 #188 for 750\n",
    "                    \n",
    "    #non-maximum suppression threshold for detection\n",
    "    DETECTION_MIN_CONFIDENCE = 0.7\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 2#num of validation images/batch size\n",
    "    \n",
    "    #EARLY STOPPING\n",
    "    EARLY_STOPPING_MONITOR = 'val_loss'\n",
    "    EARLY_STOPPING_PATIENCE = 10 #number of epochs with no improvement required to stop\n",
    "    ES_RESTORE_BEST_WEIGHTS =True\n",
    "    ES_MODE= \"min\"\n",
    "    ES_VERBOSE = 0\n",
    "    \n",
    "config = SAGEConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_ax(rows=1, cols=1, size=8):\n",
    "#    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "#    all visualizations in the notebook. Provide a\n",
    "#    central point to control graph sizes.   \n",
    "#    Change the default size attribute to control the size\n",
    "#    of rendered images\n",
    "#    \"\"\"\n",
    "#    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "#    return ax\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Create a synthetic dataset\n",
    "\n",
    "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
    "\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SAGEDataset(utils.Dataset):\n",
    "    \"\"\"Load Dataset\n",
    "    \"\"\"\n",
    "    def __init__(self,images_dir, particle_masks_dir, cluster_masks_dir, load_particle=True, load_cluster=True):\n",
    "        super().__init__()\n",
    "        self.images_dir = images_dir\n",
    "        self.particle_masks_dir = particle_masks_dir\n",
    "        self.cluster_masks_dir = cluster_masks_dir\n",
    "        self.load_particle = load_particle  # Correctly initialize the attribute\n",
    "        self.load_cluster = load_cluster  # Correctly initialize the attribute\n",
    "   \n",
    "        if load_particle and load_cluster:\n",
    "            self.class_names = [\"particle\", \"cluster\"]\n",
    "            self.add_class(\"SAGE\",1,\"particle\") #add particle class\n",
    "            self.add_class(\"SAGE\",2,\"cluster\") #add cluster class \n",
    "        elif load_particle:\n",
    "            self.class_names=[\"particle\"]\n",
    "            self.add_class(\"SAGE\",1,\"particle\") #add particle class\n",
    "        elif load_cluster:\n",
    "            self.class_names=[\"cluster\"]\n",
    "            self.add_class(\"SAGE\",1,\"cluster\") #add cluster class \n",
    "            \n",
    "        #print(self.class_names)\n",
    "    \n",
    "    def load_dataset(self):\n",
    "        \"\"\"Load images and masks from specified directories.\"\"\"\n",
    "        #load images\n",
    "        image_filenames = [f for f in os.listdir(self.images_dir) if f.endswith('.png')]\n",
    "        #print(f\"unsorted: {image_filenames}\")\n",
    "        #sort them by number\n",
    "        image_filenames.sort(key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "        #print(f\"Sorted: {image_filenames}\")\n",
    "        \n",
    "        for image_id, filename in enumerate(tqdm(image_filenames, \"Adding images\", dynamic_ncols=True)):\n",
    "            image_path = os.path.join(self.images_dir, filename)\n",
    "            image_no = filename.split('_')[1] #get image number\n",
    "            basename = os.path.splitext(filename)[0] \n",
    "            #print(basename)\n",
    "            self.add_image(\"SAGE\", image_id=image_id, path=image_path,basename=basename,width=None, height=None)\n",
    "            \n",
    "        #load masks for each image\n",
    "        \n",
    "        for image_id in tqdm(range(len(self.image_info)), desc=\"Loading masks for images\", dynamic_ncols=True):\n",
    "            self.load_mask(image_id)\n",
    "\n",
    "        \n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\" Load an image from the dataset.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        image = cv2.imread(info['path'])\n",
    "        return image\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the particle data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"SAGE\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            return super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"load instance masks for the particle of the given image ID.\"\"\"\n",
    "        \n",
    "        info = self.image_info[image_id]\n",
    "        masks = []\n",
    "        class_ids = []\n",
    "        \n",
    "        if self.load_particle and self.load_cluster:\n",
    "            masks_particle, class_ids_particle = self._load_class_masks(info, self.particle_masks_dir, class_id=1,pattern='particle')\n",
    "            #if masks_particle:\n",
    "                #print(f\"Loaded {len(masks_particle)} particle masks for Image ID {image_id}.\")\n",
    "            masks.extend(masks_particle)\n",
    "            class_ids.extend(class_ids_particle)\n",
    "            \n",
    "            masks_cluster, class_ids_cluster = self._load_class_masks(info, self.cluster_masks_dir, class_id=2,pattern='cluster')\n",
    "            #if masks_cluster:\n",
    "               # print(f\"Loaded {len(masks_cluster)} cluster masks for Image ID {image_id}.\")\n",
    "            masks.extend(masks_cluster)\n",
    "            class_ids.extend(class_ids_cluster)\n",
    "            #print(\"Both particle and cluster masks\")\n",
    "            \n",
    "        #particle masks\n",
    "        elif self.load_particle:\n",
    "            masks_particle, class_ids_particle = self._load_class_masks(info, self.particle_masks_dir, class_id=1,pattern='particle')\n",
    "            #if masks_particle:\n",
    "                #print(f\"Loaded {len(masks_particle)} particle masks for Image ID {image_id}.\")\n",
    "            masks.extend(masks_particle)\n",
    "            class_ids.extend(class_ids_particle)\n",
    "            #rint(\"only particle masks\")\n",
    "            \n",
    "        #cluster masks\n",
    "        elif self.load_cluster:\n",
    "            masks_cluster, class_ids_cluster = self._load_class_masks(info, self.cluster_masks_dir, class_id='1',pattern='cluster')\n",
    "            #if masks_cluster:\n",
    "               # print(f\"Loaded {len(masks_cluster)} cluster masks for Image ID {image_id}.\")\n",
    "            masks.extend(masks_cluster)\n",
    "            class_ids.extend(class_ids_cluster)\n",
    "           #print((\"only cluster masks\"))\n",
    "            \n",
    "        #combine masks into 3d array\n",
    "        if masks:\n",
    "            combined_mask = np.stack(masks, axis =-1)\n",
    "            return combined_mask, np.array(class_ids, dtype=np.int32)\n",
    "                      \n",
    "        #print(f\" No masks found for image ID {image_id}.\")\n",
    "        return np.zeros((0,0), dtype=np.bool_),np.zeros((0,),dtype=np.int32)\n",
    "\n",
    "    \n",
    "    def _load_class_masks(self,info, masks_dir, class_id, pattern):\n",
    "        \"\"\"Load msks for a specific class based on a pattern\"\"\"\n",
    "        \n",
    "        masks = []\n",
    "        class_ids = []\n",
    "        \n",
    "        #construct mask filename based on image filename \n",
    "        _, image_filename = os.path.split(info['path']) \n",
    "        image_no = image_filename.split('_')[1].replace('.png','') #extract the base name without the extension to form mask filename\n",
    "        #print(image_no)\n",
    "        #print(f\"Loading masks for image number:{image_no}\")\n",
    "        \n",
    "        #load all masks for the current image\n",
    "        i = 0 \n",
    "        \n",
    "        if pattern =='particle':\n",
    "            \n",
    "            i=0 \n",
    "            first_mask_found=False\n",
    "            \n",
    "            \n",
    "            while True: \n",
    "                mask_filename = f\"mask_{image_no}_{i:06d}.png\"\n",
    "                mask_path = os.path.join(masks_dir, mask_filename)\n",
    "                \n",
    "                if os.path.exists(mask_path):\n",
    "                    #print(f\"Found mask file: {mask_path}\")\n",
    "                    mask = cv2.imread(mask_path,cv2.IMREAD_GRAYSCALE) #load mask\n",
    "                    first_mask_found = True\n",
    "                    if mask is not None:\n",
    "                        masks.append(mask.astype(np.bool_))\n",
    "                        class_ids.append(class_id)\n",
    "                    i += 1\n",
    "                   \n",
    "                elif not first_mask_found:\n",
    "                    i=1\n",
    "                    continue\n",
    "                else:\n",
    "                    #print(f\"Mask file not found: {mask_path}\")\n",
    "                    break\n",
    "        elif pattern == 'cluster':\n",
    "            # For clusters, load only one mask\n",
    "            mask_filename = f\"mask_{image_no}.png\"\n",
    "            mask_path = os.path.join(masks_dir, mask_filename)\n",
    "            #print(f\"Checking path for mask: {mask_path}\")\n",
    "        \n",
    "            if os.path.exists(mask_path):\n",
    "                #print(f\"Found mask file: {mask_path}\")\n",
    "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) # Load mask\n",
    "                if mask is not None:\n",
    "                    masks.append(mask.astype(np.bool_))\n",
    "                    class_ids.append(class_id)\n",
    "            else:\n",
    "                print(f\"Mask file not found: {mask_path}\")\n",
    "        \n",
    "        return masks, class_ids\n",
    "                                 \n",
    "        \n",
    "                                \n",
    "                                 \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets:\n",
    "\n",
    "Here, load the image sets that will be used for training. Multiple can be loaded for easy access and transfer learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_register_dataset(dataset_name, results_dir , load_particle=True, load_cluster=False, create_dirs=True):\n",
    "    \n",
    "    \n",
    "    images_anlyz_dir =  os.path.join(ROOT_DIR, 'SAGE', 'data', dataset_name)    \n",
    "    particle_masks_anlyz_dir = os.path.join(images_anlyz_dir, 'particle')\n",
    "    cluster_masks_anlyz_dir = os.path.join(images_anlyz_dir, 'cluster')\n",
    "    \n",
    "    if create_dirs and results_dir:                      \n",
    "        dataset_results_dir = create_dataset_results_dirs(dataset_name, results_dir)\n",
    "    #initalize and load dataset\n",
    "    \n",
    "    dataset_analyze = SAGEDataset(images_anlyz_dir,particle_masks_anlyz_dir, cluster_masks_anlyz_dir,\n",
    "                                load_particle=load_particle, load_cluster=load_cluster)\n",
    "    \n",
    "    dataset_analyze.load_dataset()\n",
    "    dataset_analyze.prepare()\n",
    "    \n",
    "    #add loaded dataset to dictionary\n",
    "    datasets[dataset_name] = dataset_analyze\n",
    "    \n",
    "    return dataset_analyze\n",
    "    \n",
    "def print_loaded_datasets(loaded_datasets):\n",
    "    \"\"\"\n",
    "    Prints the names of all the loaded datasets.\n",
    "    \n",
    "    Args:\n",
    "        loaded_datasets (dict): Dictionary of loaded datasets where keys are dataset names.\n",
    "        \n",
    "    Usage:\n",
    "        print_loaded_datasets(loaded_datasets)\n",
    "    \"\"\"\n",
    "    if not loaded_datasets:\n",
    "        print(\"No datasets loaded.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Loaded Datasets:\")\n",
    "    for dataset_name in loaded_datasets.keys():\n",
    "        print(f\"- {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dict to store datasets\n",
    "datasets = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load first dataset training and validation dataset \n",
    "here we use NS40_train and NS40_val to train first model on synthetically generated images.\n",
    "\n",
    "Since we do not need to create a results directory for these, set results_dir = None and create_dirs = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NS40_train = load_and_register_dataset('NS40_train', results_dir=None, create_dirs=False)\n",
    "NS40_val = load_and_register_dataset('NS40_val', results_dir=None, create_dirs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also load datasets for any subsequent training, such as if we want to train using manual segmentations after synthetic.\n",
    "\n",
    "After synthetic model (SAGE$_0$) is trained, we will train that model again using a set of manual segmentations, (D1e1_train and D1e1_val). This will give us SAGE$_1$.\n",
    "\n",
    "We can train again on another set of the same images, where each image was annotated by a different analyst than in D1e1. These are D2e1_train and D2e1_val. Training SAGE$_1$ on this set gives SAGE$_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First set of manual segmentations\n",
    "D1e1_train = load_and_register_dataset('D1e1_train', results_dir=None, create_dirs=False)\n",
    "D1e1_val = load_and_register_dataset('D1e1_val', results_dir=None, create_dirs=False)\n",
    "\n",
    "#Second Set\n",
    "\n",
    "D2e1_train = load_and_register_dataset('D2e1_train', results_dir=None, create_dirs=False)\n",
    "D2e1_val = load_and_register_dataset('D2e1_val', results_dir=None, create_dirs=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name, dataset in datasets.items():\n",
    "    print(f\"\\n--- Dataset: {name} ---\")\n",
    "    if len(dataset.image_ids) ==0: \n",
    "        print(\"No images loaded\")\n",
    "        continue\n",
    "    image_id = dataset.image_ids[0]\n",
    "    print(f\"Image ID:{image_id}\")\n",
    "    \n",
    "    image = dataset.load_image(image_id)\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "    \n",
    "    print(f\"Mask shape for Image ID {image_id}: {mask.shape}\")\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "\n",
    "Now we will create and train our first model, trained on the synthetic images. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MODEL_DIR)\n",
    "\n",
    "config.STEPS_PER_EPOCH =2\n",
    "config.VALIDATION_STEPS = 1\n",
    "\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will tell it which weights to start with. \n",
    "\n",
    "Since we are starting from 'scratch', we will choose COCO weights as a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "\n",
    "\n",
    "#if you want to give it a specific path to train from:\n",
    "manual_path = os.path.join(DATA_DIR, \"logs/coco_M1e1_part/mask_rcnn_spectra_0034.h5\")\n",
    "\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with ==\"manual\":\n",
    "    #load the weights from specified path\n",
    "    model.load_weights(manual_path, by_name=True)\n",
    "\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Synthic Model (SAGE$_0$)\n",
    "\n",
    "\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "#model.train(cluster_dataset_train, cluster_dataset_val, \n",
    "#            learning_rate=config.LEARNING_RATE, \n",
    "#            epochs=100, \n",
    "#            layers='heads')\n",
    "\n",
    "\n",
    "#Define what datasets to train/validate with\n",
    "\n",
    "dataset_train = datasets.get('NS40_train', None)\n",
    "dataset_val = datasets.get('NS40_val', None)\n",
    "\n",
    "#get epoch that it stopped at\n",
    "model.train(dataset_train,dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=100, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the heads are trained, train full layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10, #changed to /5\n",
    "            epochs=200, \n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "def save_displayed_config(config, log_dir, train_path, val_path):\n",
    "    captured_output = io.StringIO()\n",
    "    sys.stdout = captured_output\n",
    "    \n",
    "    config.display()\n",
    "    \n",
    "    print(f\"Training Data Path: {train_path}\")\n",
    "    print(f\"Validation Data Path: {val_path}\")\n",
    "    sys.stdout=sys.__stdout__\n",
    "    \n",
    "    config_path_txt = os.path.join(log_dir, \"config.txt\")\n",
    "    with open(config_path_txt, \"w\") as f:\n",
    "        f.write(captured_output.getvalue())\n",
    "\n",
    "name = model.find_last()\n",
    "print(name)\n",
    "model_name=name.partition('/logs/')[2]\n",
    "print(model_name)\n",
    "folder_name = model_name.split(os.sep)[0]\n",
    "print(folder_name)\n",
    "                \n",
    "path = os.path.join(MODEL_DIR, folder_name)\n",
    "print(path)\n",
    "\n",
    "save_displayed_config(config,log_dir = path, train_path = dataset_train.particle_masks_dir, val_path =dataset_val.particle_masks_dir )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use that last model that was trained, and retrain it with our first set of manual segmentations.\n",
    "\n",
    "We can tell its to start with the weights from that model using either find_last or specifying the path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to give it a specific path to train from:\n",
    "manual_path = os.path.join(DATA_DIR, \"logs/coco_M1e1_part/mask_rcnn_spectra_0034.h5\")\n",
    "\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "\n",
    "\n",
    "if init_with ==\"manual\":\n",
    "    #load the weights from specified path\n",
    "    model.load_weights(manual_path, by_name=True)\n",
    "\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_loaded_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign new training and validaton datasets\n",
    "\n",
    "dataset_train = datasets.get('D1e1_train', None)\n",
    "dataset_val = datasets.get('D1e1_val', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "#model.train(cluster_dataset_train, cluster_dataset_val, \n",
    "#            learning_rate=config.LEARNING_RATE, \n",
    "#            epochs=100, \n",
    "#            layers='heads')\n",
    "\n",
    "#get epoch that it stopped at\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=100, \n",
    "            layers='heads',\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "\n",
    "#model.train(cluster_dataset_train, cluster_dataset_val, \n",
    "  #          learning_rate=config.LEARNING_RATE / 5, #changed to /5\n",
    "   #         epochs=200, \n",
    "    #        layers=\"all\")\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10, #changed to /5\n",
    "            epochs=200, \n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = model.find_last()\n",
    "print(name)\n",
    "model_name=name.partition('/logs/')[2]\n",
    "print(model_name)\n",
    "folder_name = model_name.split(os.sep)[0]\n",
    "print(folder_name)\n",
    "\n",
    "save_displayed_config(config,log_dir = path, train_path = dataset_train.particle_masks_dir, val_path =dataset_val.particle_masks_dir )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we repeat the same process with the 2nd set of manual segmentations, D2e1_train, and D2e1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to give it a specific path to train from:\n",
    "manual_path = os.path.join(DATA_DIR, \"logs/coco_M1e1_part/mask_rcnn_spectra_0034.h5\")\n",
    "\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "\n",
    "\n",
    "if init_with ==\"manual\":\n",
    "    #load the weights from specified path\n",
    "    model.load_weights(manual_path, by_name=True)\n",
    "\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_loaded_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "#model.train(cluster_dataset_train, cluster_dataset_val, \n",
    "#            learning_rate=config.LEARNING_RATE, \n",
    "#            epochs=100, \n",
    "#            layers='heads')\n",
    "\n",
    "#get epoch that it stopped at\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=100, \n",
    "            layers='heads',\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "\n",
    "#model.train(cluster_dataset_train, cluster_dataset_val, \n",
    "  #          learning_rate=config.LEARNING_RATE / 5, #changed to /5\n",
    "   #         epochs=200, \n",
    "    #        layers=\"all\")\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10, #changed to /5\n",
    "            epochs=200, \n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = model.find_last()\n",
    "print(name)\n",
    "model_name=name.partition('/logs/')[2]\n",
    "print(model_name)\n",
    "folder_name = model_name.split(os.sep)[0]\n",
    "print(folder_name)\n",
    "\n",
    "save_displayed_config(config,log_dir = path, train_path = dataset_train.particle_masks_dir, val_path =dataset_val.particle_masks_dir )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
